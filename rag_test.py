from sentence_transformers import SentenceTransformer
from transformers import pipeline
import faiss
import numpy as np
import glob
import os
from dotenv import load_dotenv
from openai import OpenAI

# === 0. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ===
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

client = OpenAI(api_key=api_key)

# === 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ===
def load_documents(folder_path="data"):
    docs = []
    for path in glob.glob(os.path.join(folder_path, "*.txt")):
        with open(path, "r", encoding="utf-8") as f:
            text = f.read().strip()
            docs.append(text)
    return docs

# === 2. ãƒ™ã‚¯ãƒˆãƒ«åŒ– ===
def create_embeddings(docs):
    model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
    embeddings = model.encode(docs, convert_to_numpy=True)
    return model, np.array(embeddings)

# === 3. æ¤œç´¢é–¢æ•° ===
def search(query, embedder, index, docs, top_k=2):
    q_emb = embedder.encode([query])
    D, I = index.search(np.array(q_emb), top_k)
    return [docs[i] for i in I[0]]

# === 4. LLMï¼ˆLlamaã‚„Phiï¼‰ã§å›ç­”ç”Ÿæˆ ===
def answer(query, retriever):
    context = "\n".join(retriever(query))
    prompt = f"""
ã‚ãªãŸã¯äº¬éƒ½ã®è¦³å…‰ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚
æ¬¡ã®æƒ…å ±ã‚’å‚è€ƒã«ã€è³ªå•ã«ç°¡æ½”ã§è‡ªç„¶ãªæ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
ã‚¯ã‚¤ã‚ºã®ã‚ˆã†ãªå½¢å¼ã§ã¯ãªãã€æ™®é€šã®èª¬æ˜æ–‡ã§ç­”ãˆã¦ãã ã•ã„ã€‚
ä¸æ˜ãªå ´åˆã¯ã€Œåˆ†ã‹ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚

ã€å‚è€ƒæƒ…å ±ã€‘
{context}

ã€è³ªå•ã€‘
{query}

ã€å›ç­”ã€‘
    """
    res = client.chat.completions.create(
        model="ft:gpt-4o-mini-2024-07-18:keitaro::CRXr0O9Q",  # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
        max_tokens=100
    )
    return res.choices[0].message.content.strip()

# === ãƒ¡ã‚¤ãƒ³å‡¦ç† ===
if __name__ == "__main__":
    print("ğŸ”¹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
    docs = load_documents("data")

    print("ğŸ”¹ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
    embedder, embeddings = create_embeddings(docs)

    print("ğŸ”¹ FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)

    retriever = lambda q: search(q, embedder, index, docs)


    print("âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼ï¼ˆè‡ªä½œãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ« ä½¿ç”¨ä¸­ï¼‰")

    while True:
        query = input("\nğŸ—£ è³ªå•ã‚’ã©ã†ãï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯exitï¼‰: ")
        if query.lower() in ["exit", "quit"]:
            break
        response = answer(query, retriever)
        print("\nğŸ¤– å›ç­”:\n", response)
